{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non-Myopic Bayesian Optimization: Towards Non-Trivial Horizons \n",
    "For the sake of simplicity, we'll focus first on 1D problems and then generalize of programming framework to hand nD problems.\n",
    "\n",
    "## Questions & Concerns\n",
    "- If we return functional objects, we can simulate having a handle on our Gaussian Process as it evolves in time cheaply by evaluating each instance\n",
    "  on an as needed basis. The most costly thing would be having to keep track of the handles to such in some type of dictionary.\n",
    "\n",
    "## What's Next?\n",
    "\n",
    "- [x] Finish LaTeX on analytic formulation of expected improvement in 1d.\n",
    "- [x] Write code to implement expected improvement in 1d.\n",
    "- [ ] Once the BO loop can solve this problem in 1d, work on computing trajectories and add code to support such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using LinearAlgebra\n",
    "using Optim\n",
    "using Plots\n",
    "using Statistics\n",
    "using Zygote\n",
    "\n",
    "import Base.@kwdef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type Kernel end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessory and Utility Methods + Black Box Process\n",
    "A pretty laborious thing to code is the construction of our covariances matrices with respect to different variates, so we abstract away this process. Provided that\n",
    "you specify your kernel of choice and provide it access to a collection of both your variates, then we can easily construct such a matrix. We also accept a noise\n",
    "parameter, however, I believe this should be encapsulated elsewhere (for storage purposes) because I'm sure we'll need access to it again.\n",
    "\n",
    "Here, we assume that our `Black Box Process` is known, although, in practice, it isn't. We assume a strict analytical form, of which, we can sample from with or\n",
    "without noise over the interval $[-1, 2]$.\n",
    "$$\n",
    "f_\\sigma (x) = \\alpha \\cdot (-sin(3x) -x^2 + .7x) + \\sigma \\epsilon\n",
    "$$\n",
    "where $\\alpha \\in \\mathbb{R}$ is a scale factor and $\\epsilon \\sim \\mathcal{N}(0, 1)$\n",
    "\n",
    "\n",
    "#### CovarianceMatrix\n",
    "Arguments:\n",
    "* kernel::Kernel: a kernel functor that evaluates the covariance between two vectors\n",
    "* Xa::Array{Float64, 2}: a matrix of variates\n",
    "* Xb::Array{Float64, 2}: a matrix of variates\n",
    "* $\\sigma$noise::Real: noise term \n",
    "\n",
    "Constructs a covariance matrix between the given matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toMatrix (generic function with 1 method)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function blackBoxProcess(xloc::Float64; σnoise::Float64=.1)\n",
    "    # Domain of interest (for f) is restricted to [-1, 2]\n",
    "    scale_factor = 1.\n",
    "    horizontal_shift = 0\n",
    "    f(x; σ=σnoise) = scale_factor * (-sin(3x) - x^2 + .7x + horizontal_shift) + σ*randn()\n",
    "    return f(xloc)\n",
    "end\n",
    "\n",
    "# Matrix will be xlength x ylength: every row corresponds to an element from x\n",
    "# More generally, the covariance between two entities can be vector valued\n",
    "function covarianceMatrix(kernel::Kernel, Xa::Array{Float64, 2}, Xb::Array{Float64, 2}; σnoise::Real=0.0)\n",
    "    @assert size(Xa)[1] == size(Xb)[1]\n",
    "    @assert isempty(methods(kernel)) == false\n",
    "    \n",
    "    # Kernel should be a function of two arguments\n",
    "    xalength = size(Xa)[2] # rows here correspond to dimensionality\n",
    "    xblength = size(Xb)[2]\n",
    "    covMatrix = zeros(xalength, xblength)\n",
    "\n",
    "    for xacol in 1:xalength\n",
    "        for xbcol in 1:xblength\n",
    "            δkronecker = xacol == xbcol ? σnoise^2 * 1 : 0\n",
    "            covMatrix[xacol, xbcol] = kernel(Xa[:, xacol], Xb[:, xbcol]) + δkronecker\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return covMatrix\n",
    "end\n",
    "\n",
    "function toMatrix(x::Float64)\n",
    "    return reshape([x], (1, 1))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kernels as Structs\n",
    "Here, we represent support for each kernel as a struct. Each struct accepts hyperparameters, associated with the respective kernel, as named arguments\n",
    "and returns a handle on the object. Each object is callable and represents computing $k(x_a, x_b)$. Every kernel has an output variance/scale factor associated with, which we'll call `variance`. We also take into account noisy situations as well which is denoted as `noise` and is squared\n",
    "internally.\n",
    "\n",
    "`Squared Exponential Kernel`: $k(x, x') = \\nu^2 exp(-\\frac{(x - x')^2}{2l^2}) + \\sigma_{noise}^2 \\delta_{xx'}$\n",
    "\n",
    "### Design Choices\n",
    "I want each kernel's hyperparameters to be name specified to avoid ambuguity with ordered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SquaredExponential"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kwdef mutable struct SquaredExponential <: Kernel\n",
    "    variance::Real # provided as ν²\n",
    "    lengthscale::Real # provided as l\n",
    "    noise::Real # provided as σ\n",
    "    \n",
    "    function SquaredExponential(variance, lengthscale, noise)\n",
    "        @assert variance >= 0 \"variance must be a positive real number\"\n",
    "        \n",
    "        return new(variance, lengthscale, noise)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "SquaredExponential() = SquaredExponential(variance=1.0, lengthscale=1.0, noise=0.0)\n",
    "SE() = SquaredExponential()\n",
    "\n",
    "function (se::SquaredExponential)(x::Array{Float64, 1}, y::Array{Float64, 1})::Real\n",
    "    δxx = Int8(x == y)\n",
    "    r = x - y\n",
    "    ρ = norm(r, 2)\n",
    "    return se.variance * exp(-ρ^2 / 2*se.lengthscale^2) + δxx*se.noise^2\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1×201 Array{Float64,2}:\n",
       " -107.988  -105.929  -103.803  -101.615  …  -88.2774  -90.0905  -92.012"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suppose we have some process and we have n known function evaluations\n",
    "n = 2\n",
    "d = 1\n",
    "σnoise = 0.05\n",
    "\n",
    "# D x n, D: dimensions, n: number of observations\n",
    "X = round.(\n",
    "    rand(Uniform(-1., 2.), d, n), \n",
    "    digits=4\n",
    ") \n",
    "y = vec(blackBoxProcess.(X; σnoise=σnoise))\n",
    "\n",
    "# Let's sample from our predictive distribution conditioned on our observations\n",
    "# across the interval [-1, 2] to observe some reasonable functions\n",
    "Xtrue = collect(-10.0:.1:10.0)\n",
    "Xtrue = reshape(Xtrue, (1, length(Xtrue)))\n",
    "ytrue = blackBoxProcess.(Xtrue; σnoise=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Processes as Structs\n",
    "It'd be very convenient for us to encapsulate information associated with GPs into a struct. It's immediately obvious, that the predictive mean and \n",
    "predictive variance rely on similar information and computing and storing such information multiple times is redundant and can become expensive in\n",
    "higher dimensional settings. I'm making a design choice here of accepting the kernel and mean function as function objects instead of vectors. Multiple constructor methods will be supported, but for the time-being, we'll focus on one.\n",
    "\n",
    "*Gaussian Process State*\n",
    "\n",
    "`Mean Function`: a function like object representing the mean of the observations\n",
    "\n",
    "`Covariance Function`: a function like object used to compute the covariance matrix between observations\n",
    "\n",
    "`Cholesky Matrix`: from the cholesky factor, we should be able to reconstruct our covariance matrix since the cholesky factorization of a positive semi-definite matrix is \n",
    "unique.\n",
    "\n",
    "`Cholesky Solve (alpha)`: $\\alpha := L^T \\backslash (L \\backslash y)$,\n",
    "\n",
    "### Gaussian Process Utility Methods\n",
    "`Conditional`: conditioning the GP on inputs and targets should take the internal covariance function and compute the predictive mean and predictive variance\n",
    "* Or, we compute the alpha term which is then used by our predictive variance and predictive mean. So, each time we return a handle on the predictive mean and predictive\n",
    "  variance, we ensure that the alpha term has been computed (which will take place in conditional). We may\n",
    "\n",
    "`Predictive Mean`: a function that accepts a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Union{Nothing, Type} where Type"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Helper method for ensuring an object is callable\n",
    "isCallable(f) = !isempty(methods(f))\n",
    "const DataOrNothing{Type} = Union{Type, Nothing}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcess"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kwdef mutable struct GaussianProcess\n",
    "    meanFunction\n",
    "    covarianceFunction::Kernel\n",
    "    choleskyFactor::DataOrNothing{AbstractMatrix{Float64}}\n",
    "    choleskySolve::DataOrNothing{AbstractVector{Float64}}\n",
    "    predictiveVariance\n",
    "    predictiveMean\n",
    "    \n",
    "    function GaussianProcess(mean, kernel)\n",
    "        @assert isCallable(mean) == true\n",
    "        @assert isCallable(kernel) == true\n",
    "\n",
    "        return new(\n",
    "            mean,\n",
    "            kernel,\n",
    "            nothing,\n",
    "            nothing,\n",
    "            nothing,\n",
    "            nothing\n",
    "        )\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GP (generic function with 1 method)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GP(mean, kernel) = GaussianProcess(mean, kernel)\n",
    "\n",
    "# add a constructor method for accepting the other factors and returns a new copy\n",
    "# of a GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "covarianceMatrix (generic function with 2 methods)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function covarianceMatrix(gp::GaussianProcess)::Union{AbstractMatrix{Float64}, Nothing}\n",
    "    if isnothing(gp.choleskyFactor) return nothing end\n",
    "    return gp.choleskyFactor * gp.choleskyFactor'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "covarianceMatrix(GP(()-> 0., SE()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Optimization as Structs\n",
    "In order to perform the iteration, efficient utilization of state is necessary. Abstracting away unnecessary state from our Gaussian Process is necessary. Mathematically,\n",
    "a Gaussian Process is completely defined by it's mean function and covariance function. Thus, programmatically, we'll leave it the same. It does need data to perform useful\n",
    "operations, so we'll provide that by wrapping the iteration into a Bayesian Optimization struct and maintaining supplementary state here.\n",
    "\n",
    "*Bayesian Optimization State*\n",
    "\n",
    "`Samples/Variates X`: We enforce that the observations provided are $\\mathbb{R}^{D \\times n}$, where $D := $ the dimensionality of the variates and $n := $ is the number of\n",
    "observations.\n",
    "\n",
    "`Values/Covariates y`: We further enforce that the observations are provided as column vector $v \\in \\mathbb{R}^{n}$\n",
    "\n",
    "`Best Observation ybest`: Since we're usually dealing with sparse data initially, we find the best value from the given covariates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianOptimization"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@kwdef mutable struct BayesianOptimization\n",
    "    gp::GaussianProcess\n",
    "    X::DataOrNothing{AbstractMatrix{Float64}}\n",
    "    y::DataOrNothing{AbstractVector{Float64}}\n",
    "    ybest::Float64\n",
    "    xi::Float64 # exploration parameter\n",
    "    \n",
    "    function BayesianOptimization(gp::GaussianProcess, X::Array{Float64, 2}, y::Array{Float64, 1})\n",
    "        @assert size(X)[2] == length(y) \"each variate must have a corresponding covariate:\" # may cause issues when generalizing to vector valued functions\n",
    "        \n",
    "        return new(gp, X, y, maximum(y)) \n",
    "    end\n",
    "end "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BO (generic function with 1 method)"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BO(gp, X, y) = BayesianOptimization(gp, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conditional (generic function with 1 method)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function sample(gp::GaussianProcess, xloc::Float64)\n",
    "    # Want to sample from a multivariate normal which is centered at the predictive\n",
    "    # mean with covariance matrix defined by the GPs kernel matrix\n",
    "    # To generate a sample at location xloc, we must compute the predictive mean and predictive variance\n",
    "    # at the location and sample from a mvn with mean and covariance specified as such\n",
    "    μxloc = gp.predictiveMean(xloc)\n",
    "    σxloc = gp.predictiveVariance(xloc)\n",
    "    uninorm = Normal(μxloc, σxloc^2)\n",
    "    return nsamples::Int64 -> rand(uninorm, nsamples)\n",
    "end\n",
    "\n",
    "# function pseudoConditional(gp::GaussianProcess, x::Array{Float64, 1})\n",
    "    \n",
    "# end\n",
    "\n",
    "function conditional(bopt::BayesianOptimization, X::Array{Float64, 2}, y::Array{Float64, 1}, σnoise::Float64)\n",
    "    priorData = bopt.X\n",
    "    posteriorData = X\n",
    "    priorDataCovariates = bopt.y\n",
    "    posteriorDataCovariates = y\n",
    "    \n",
    "    if isnothing(bopt.gp.choleskyFactor) # initialize our model\n",
    "        KXX = covarianceMatrix(bopt.gp.covarianceFunction, priorData, priorData; σnoise=σnoise) # bopt.gp.covarianceFunction.noise instead of σnoise\n",
    "        KXX = Matrix(Hermitian(KXX))\n",
    "        bopt.gp.choleskyFactor = cholesky(KXX).U'\n",
    "    else # update our model\n",
    "        L = bopt.gp.choleskyFactor\n",
    "        KXX = Matrix(Hermitian(L*L'))\n",
    "        KXS = covarianceMatrix(bopt.gp.covarianceFunction, priorData, posteriorData; σnoise=σnoise)\n",
    "        KSS = covarianceMatrix(bopt.gp.covarianceFunction, posteriorData, posteriorData; σnoise=σnoise)\n",
    "        KXplusS = [KXX KXS;\n",
    "                   KXS' KSS]\n",
    "        KXplusS = Matrix(Hermitian(KXplusS))\n",
    "        bopt.gp.choleskyFactor = cholesky(KXplusS).U'\n",
    "        # update bopt with new observations\n",
    "        bopt.X = hcat(bopt.X, X)\n",
    "        bopt.y = vcat(bopt.y, y)\n",
    "        bopt.ybest = maximum(bopt.y)\n",
    "    end\n",
    "    \n",
    "    L = bopt.gp.choleskyFactor\n",
    "    bopt.gp.choleskySolve = L'\\(L\\bopt.y)\n",
    "    \n",
    "    # construct predictive mean function\n",
    "    function μ(xtest)\n",
    "        xtest = toMatrix(xtest)\n",
    "        kxs = covarianceMatrix(bopt.gp.covarianceFunction, bopt.X, xtest; σnoise=σnoise)\n",
    "        return dot(kxs, bopt.gp.choleskySolve)\n",
    "    end\n",
    "    \n",
    "    bopt.gp.predictiveMean = μ\n",
    "    \n",
    "    # construct predictive variance function\n",
    "    function σsquared(xtest)\n",
    "        xtest = toMatrix(xtest)\n",
    "        kxs = covarianceMatrix(bopt.gp.covarianceFunction, bopt.X, xtest; σnoise=σnoise)\n",
    "        v = bopt.gp.choleskyFactor \\ kxs\n",
    "        kss = covarianceMatrix(bopt.gp.covarianceFunction, xtest, xtest; σnoise=σnoise)[1][1]\n",
    "        return kss - dot(v, v)\n",
    "    end\n",
    "    \n",
    "    bopt.gp.predictiveVariance = σsquared\n",
    "    \n",
    "    return\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip880\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip880)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip881\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip880)\" d=\"\n",
       "M147.478 1486.45 L2352.76 1486.45 L2352.76 47.2441 L147.478 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip882\">\n",
       "    <rect x=\"147\" y=\"47\" width=\"2206\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  209.891,1486.45 209.891,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  903.375,1486.45 903.375,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1596.86,1486.45 1596.86,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2290.34,1486.45 2290.34,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.478,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  209.891,1486.45 209.891,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  903.375,1486.45 903.375,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1596.86,1486.45 1596.86,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2290.34,1486.45 2290.34,1469.18 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip880)\" d=\"M 0 0 M179.649 1530.29 L209.324 1530.29 L209.324 1534.23 L179.649 1534.23 L179.649 1530.29 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M220.227 1543.18 L227.866 1543.18 L227.866 1516.82 L219.556 1518.49 L219.556 1514.23 L227.82 1512.56 L232.495 1512.56 L232.495 1543.18 L240.134 1543.18 L240.134 1547.12 L220.227 1547.12 L220.227 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M903.375 1515.64 Q899.764 1515.64 897.935 1519.2 Q896.13 1522.75 896.13 1529.87 Q896.13 1536.98 897.935 1540.55 Q899.764 1544.09 903.375 1544.09 Q907.009 1544.09 908.815 1540.55 Q910.644 1536.98 910.644 1529.87 Q910.644 1522.75 908.815 1519.2 Q907.009 1515.64 903.375 1515.64 M903.375 1511.93 Q909.185 1511.93 912.241 1516.54 Q915.319 1521.12 915.319 1529.87 Q915.319 1538.6 912.241 1543.21 Q909.185 1547.79 903.375 1547.79 Q897.565 1547.79 894.486 1543.21 Q891.431 1538.6 891.431 1529.87 Q891.431 1521.12 894.486 1516.54 Q897.565 1511.93 903.375 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M1587.24 1543.18 L1594.88 1543.18 L1594.88 1516.82 L1586.57 1518.49 L1586.57 1514.23 L1594.83 1512.56 L1599.51 1512.56 L1599.51 1543.18 L1607.15 1543.18 L1607.15 1547.12 L1587.24 1547.12 L1587.24 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2285 1543.18 L2301.31 1543.18 L2301.31 1547.12 L2279.37 1547.12 L2279.37 1543.18 Q2282.03 1540.43 2286.62 1535.8 Q2291.22 1531.15 2292.4 1529.81 Q2294.65 1527.28 2295.53 1525.55 Q2296.43 1523.79 2296.43 1522.1 Q2296.43 1519.34 2294.49 1517.61 Q2292.56 1515.87 2289.46 1515.87 Q2287.26 1515.87 2284.81 1516.63 Q2282.38 1517.4 2279.6 1518.95 L2279.6 1514.23 Q2282.43 1513.09 2284.88 1512.51 Q2287.33 1511.93 2289.37 1511.93 Q2294.74 1511.93 2297.93 1514.62 Q2301.13 1517.31 2301.13 1521.8 Q2301.13 1523.93 2300.32 1525.85 Q2299.53 1527.74 2297.43 1530.34 Q2296.85 1531.01 2293.75 1534.23 Q2290.64 1537.42 2285 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.478,1315.3 2352.76,1315.3 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.478,908.484 2352.76,908.484 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.478,501.67 2352.76,501.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#000000; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  147.478,94.8566 2352.76,94.8566 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.478,1486.45 147.478,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.478,1315.3 173.941,1315.3 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.478,908.484 173.941,908.484 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.478,501.67 173.941,501.67 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  147.478,94.8566 173.941,94.8566 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip880)\" d=\"M 0 0 M51.3625 1315.75 L81.0383 1315.75 L81.0383 1319.68 L51.3625 1319.68 L51.3625 1315.75 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M95.1586 1328.64 L111.478 1328.64 L111.478 1332.58 L89.5336 1332.58 L89.5336 1328.64 Q92.1956 1325.89 96.7789 1321.26 Q101.385 1316.61 102.566 1315.26 Q104.811 1312.74 105.691 1311 Q106.594 1309.24 106.594 1307.55 Q106.594 1304.8 104.649 1303.06 Q102.728 1301.33 99.6261 1301.33 Q97.4271 1301.33 94.9734 1302.09 Q92.5428 1302.86 89.7651 1304.41 L89.7651 1299.68 Q92.5891 1298.55 95.0428 1297.97 Q97.4965 1297.39 99.5335 1297.39 Q104.904 1297.39 108.098 1300.08 Q111.293 1302.76 111.293 1307.25 Q111.293 1309.38 110.483 1311.3 Q109.696 1313.2 107.589 1315.8 Q107.01 1316.47 103.909 1319.68 Q100.807 1322.88 95.1586 1328.64 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M50.9921 908.935 L80.6679 908.935 L80.6679 912.87 L50.9921 912.87 L50.9921 908.935 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M91.5706 921.829 L99.2095 921.829 L99.2095 895.463 L90.8993 897.13 L90.8993 892.871 L99.1632 891.204 L103.839 891.204 L103.839 921.829 L111.478 921.829 L111.478 925.764 L91.5706 925.764 L91.5706 921.829 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M99.5335 487.469 Q95.9224 487.469 94.0937 491.034 Q92.2882 494.575 92.2882 501.705 Q92.2882 508.811 94.0937 512.376 Q95.9224 515.918 99.5335 515.918 Q103.168 515.918 104.973 512.376 Q106.802 508.811 106.802 501.705 Q106.802 494.575 104.973 491.034 Q103.168 487.469 99.5335 487.469 M99.5335 483.765 Q105.344 483.765 108.399 488.372 Q111.478 492.955 111.478 501.705 Q111.478 510.432 108.399 515.038 Q105.344 519.622 99.5335 519.622 Q93.7234 519.622 90.6447 515.038 Q87.5892 510.432 87.5892 501.705 Q87.5892 492.955 90.6447 488.372 Q93.7234 483.765 99.5335 483.765 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M91.5706 108.201 L99.2095 108.201 L99.2095 81.8358 L90.8993 83.5025 L90.8993 79.2433 L99.1632 77.5766 L103.839 77.5766 L103.839 108.201 L111.478 108.201 L111.478 112.137 L91.5706 112.137 L91.5706 108.201 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><circle clip-path=\"url(#clip882)\" cx=\"1950.6\" cy=\"617.564\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<circle clip-path=\"url(#clip882)\" cx=\"338.325\" cy=\"749.982\" r=\"14\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"3.2\"/>\n",
       "<path clip-path=\"url(#clip882)\" d=\"\n",
       "M209.891 902.167 L279.24 837.114 L348.588 808.433 L417.937 857.729 L487.285 926.336 L556.633 993.935 L625.982 1056.5 L695.33 1112.32 L764.678 1160.31 L834.027 1199.7 \n",
       "  L903.375 1229.92 L972.723 1250.61 L1042.07 1261.53 L1111.42 1262.59 L1180.77 1253.81 L1250.12 1235.33 L1319.47 1207.39 L1388.81 1170.33 L1458.16 1124.61 L1527.51 1070.81 \n",
       "  L1596.86 1009.63 L1666.21 941.896 L1735.56 868.562 L1804.9 790.691 L1874.25 709.446 L1943.6 626.056 L2012.95 686.336 L2082.3 761.759 L2151.65 834.784 L2220.99 904.245 \n",
       "  L2290.34 969.16 L2290.34 220.328 L2220.99 296.102 L2151.65 375.633 L2082.3 457.907 L2012.95 541.788 L1943.6 609.827 L1874.25 533.654 L1804.9 459.295 L1735.56 388.243 \n",
       "  L1666.21 321.951 L1596.86 261.794 L1527.51 209.026 L1458.16 164.747 L1388.81 129.881 L1319.47 105.155 L1250.12 91.0867 L1180.77 87.9763 L1111.42 95.9053 L1042.07 114.735 \n",
       "  L972.723 144.106 L903.375 183.446 L834.027 231.972 L764.678 288.697 L695.33 352.431 L625.982 421.779 L556.633 495.069 L487.285 570.065 L417.937 642.328 L348.588 691.236 \n",
       "  L279.24 657.96 L209.891 584.079  Z\n",
       "  \" fill=\"#e26f46\" fill-rule=\"evenodd\" fill-opacity=\"0.5\"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  209.891,743.123 279.24,747.537 348.588,749.835 417.937,750.028 487.285,748.2 556.633,744.502 625.982,739.141 695.33,732.378 764.678,724.505 834.027,715.834 \n",
       "  903.375,706.683 972.723,697.355 1042.07,688.13 1111.42,679.245 1180.77,670.893 1250.12,663.208 1319.47,656.271 1388.81,650.104 1458.16,644.678 1527.51,639.918 \n",
       "  1596.86,635.712 1666.21,631.924 1735.56,628.402 1804.9,624.993 1874.25,621.55 1943.6,617.942 2012.95,614.062 2082.3,609.833 2151.65,605.208 2220.99,600.173 \n",
       "  2290.34,594.744 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip882)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  209.891,1135.84 279.24,913.618 348.588,715.059 417.937,549.182 487.285,422.81 556.633,339.964 625.982,301.502 695.33,305.046 764.678,345.192 834.027,413.994 \n",
       "  903.375,501.67 972.723,597.483 1042.07,690.693 1111.42,771.521 1180.77,832.019 1250.12,866.783 1319.47,873.436 1388.81,852.836 1458.16,809.003 1527.51,748.761 \n",
       "  1596.86,681.124 1666.21,616.495 1735.56,565.735 1804.9,539.192 1874.25,545.779 1943.6,592.174 2012.95,682.229 2082.3,816.619 2151.65,992.79 2220.99,1205.18 \n",
       "  2290.34,1445.72 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip880)\" d=\"\n",
       "M1770.17 337.138 L2279.25 337.138 L2279.25 95.2176 L1770.17 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip880)\" style=\"stroke:#000000; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1770.17,337.138 2279.25,337.138 2279.25,95.2176 1770.17,95.2176 1770.17,337.138 \n",
       "  \"/>\n",
       "<circle clip-path=\"url(#clip880)\" cx=\"1868.18\" cy=\"155.698\" r=\"23\" fill=\"#009af9\" fill-rule=\"evenodd\" fill-opacity=\"1\" stroke=\"#000000\" stroke-opacity=\"1\" stroke-width=\"5.12\"/>\n",
       "<path clip-path=\"url(#clip880)\" d=\"M 0 0 M1980.03 175.385 Q1978.23 180.015 1976.51 181.427 Q1974.8 182.839 1971.93 182.839 L1968.53 182.839 L1968.53 179.274 L1971.03 179.274 Q1972.79 179.274 1973.76 178.44 Q1974.73 177.607 1975.91 174.505 L1976.68 172.561 L1966.19 147.052 L1970.7 147.052 L1978.81 167.329 L1986.91 147.052 L1991.42 147.052 L1980.03 175.385 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M1998.71 169.042 L2006.35 169.042 L2006.35 142.677 L1998.04 144.343 L1998.04 140.084 L2006.31 138.418 L2010.98 138.418 L2010.98 169.042 L2018.62 169.042 L2018.62 172.978 L1998.71 172.978 L1998.71 169.042 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip880)\" style=\"stroke:#e26f46; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1794.67,216.178 1941.69,216.178 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip880)\" d=\"M 0 0 M1966.19 198.898 L1973.16 198.898 L1981.98 222.416 L1990.84 198.898 L1997.81 198.898 L1997.81 233.458 L1993.25 233.458 L1993.25 203.11 L1984.34 226.814 L1979.64 226.814 L1970.73 203.11 L1970.73 233.458 L1966.19 233.458 L1966.19 198.898 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2029.08 219.43 L2029.08 221.513 L2009.5 221.513 Q2009.78 225.911 2012.14 228.226 Q2014.52 230.518 2018.76 230.518 Q2021.21 230.518 2023.51 229.916 Q2025.82 229.314 2028.09 228.11 L2028.09 232.138 Q2025.8 233.11 2023.39 233.62 Q2020.98 234.129 2018.51 234.129 Q2012.3 234.129 2008.67 230.518 Q2005.06 226.907 2005.06 220.749 Q2005.06 214.384 2008.48 210.657 Q2011.93 206.907 2017.76 206.907 Q2023 206.907 2026.03 210.286 Q2029.08 213.643 2029.08 219.43 M2024.82 218.18 Q2024.78 214.685 2022.86 212.601 Q2020.96 210.518 2017.81 210.518 Q2014.25 210.518 2012.09 212.532 Q2009.96 214.546 2009.64 218.203 L2024.82 218.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2047.86 220.425 Q2042.7 220.425 2040.7 221.606 Q2038.71 222.786 2038.71 225.634 Q2038.71 227.902 2040.2 229.245 Q2041.7 230.564 2044.27 230.564 Q2047.81 230.564 2049.94 228.064 Q2052.09 225.541 2052.09 221.374 L2052.09 220.425 L2047.86 220.425 M2056.35 218.666 L2056.35 233.458 L2052.09 233.458 L2052.09 229.522 Q2050.63 231.883 2048.46 233.018 Q2046.28 234.129 2043.13 234.129 Q2039.15 234.129 2036.79 231.907 Q2034.45 229.661 2034.45 225.911 Q2034.45 221.536 2037.37 219.314 Q2040.31 217.092 2046.12 217.092 L2052.09 217.092 L2052.09 216.675 Q2052.09 213.735 2050.15 212.138 Q2048.23 210.518 2044.73 210.518 Q2042.51 210.518 2040.4 211.05 Q2038.3 211.583 2036.35 212.647 L2036.35 208.712 Q2038.69 207.81 2040.89 207.37 Q2043.09 206.907 2045.17 206.907 Q2050.8 206.907 2053.57 209.823 Q2056.35 212.74 2056.35 218.666 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2086.68 217.809 L2086.68 233.458 L2082.42 233.458 L2082.42 217.948 Q2082.42 214.268 2080.98 212.439 Q2079.55 210.61 2076.68 210.61 Q2073.23 210.61 2071.24 212.81 Q2069.25 215.009 2069.25 218.805 L2069.25 233.458 L2064.96 233.458 L2064.96 207.532 L2069.25 207.532 L2069.25 211.56 Q2070.77 209.222 2072.83 208.064 Q2074.92 206.907 2077.63 206.907 Q2082.09 206.907 2084.38 209.685 Q2086.68 212.439 2086.68 217.809 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2120.29 210.518 Q2116.86 210.518 2114.87 213.203 Q2112.88 215.865 2112.88 220.518 Q2112.88 225.171 2114.85 227.856 Q2116.84 230.518 2120.29 230.518 Q2123.69 230.518 2125.68 227.833 Q2127.67 225.147 2127.67 220.518 Q2127.67 215.911 2125.68 213.226 Q2123.69 210.518 2120.29 210.518 M2120.29 206.907 Q2125.84 206.907 2129.01 210.518 Q2132.19 214.129 2132.19 220.518 Q2132.19 226.884 2129.01 230.518 Q2125.84 234.129 2120.29 234.129 Q2114.71 234.129 2111.54 230.518 Q2108.39 226.884 2108.39 220.518 Q2108.39 214.129 2111.54 210.518 Q2114.71 206.907 2120.29 206.907 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2152.37 197.439 L2152.37 200.981 L2148.3 200.981 Q2146 200.981 2145.1 201.907 Q2144.22 202.833 2144.22 205.24 L2144.22 207.532 L2151.24 207.532 L2151.24 210.842 L2144.22 210.842 L2144.22 233.458 L2139.94 233.458 L2139.94 210.842 L2135.87 210.842 L2135.87 207.532 L2139.94 207.532 L2139.94 205.726 Q2139.94 201.398 2141.95 199.43 Q2143.97 197.439 2148.34 197.439 L2152.37 197.439 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2194.75 228.527 L2194.75 219.245 L2187.12 219.245 L2187.12 215.402 L2199.38 215.402 L2199.38 230.24 Q2196.68 232.161 2193.41 233.157 Q2190.15 234.129 2186.44 234.129 Q2178.34 234.129 2173.76 229.407 Q2169.2 224.661 2169.2 216.212 Q2169.2 207.74 2173.76 203.018 Q2178.34 198.273 2186.44 198.273 Q2189.82 198.273 2192.86 199.106 Q2195.91 199.939 2198.48 201.56 L2198.48 206.536 Q2195.89 204.337 2192.97 203.226 Q2190.06 202.115 2186.84 202.115 Q2180.5 202.115 2177.3 205.657 Q2174.13 209.198 2174.13 216.212 Q2174.13 223.203 2177.3 226.745 Q2180.5 230.286 2186.84 230.286 Q2189.31 230.286 2191.26 229.87 Q2193.2 229.43 2194.75 228.527 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2212.6 202.74 L2212.6 215.726 L2218.48 215.726 Q2221.75 215.726 2223.53 214.036 Q2225.31 212.347 2225.31 209.222 Q2225.31 206.12 2223.53 204.43 Q2221.75 202.74 2218.48 202.74 L2212.6 202.74 M2207.93 198.898 L2218.48 198.898 Q2224.29 198.898 2227.25 201.536 Q2230.24 204.152 2230.24 209.222 Q2230.24 214.337 2227.25 216.953 Q2224.29 219.569 2218.48 219.569 L2212.6 219.569 L2212.6 233.458 L2207.93 233.458 L2207.93 198.898 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip880)\" style=\"stroke:#3da44d; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1794.67,276.658 1941.69,276.658 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip880)\" d=\"M 0 0 M1982.21 262.549 Q1977.12 262.549 1974.11 266.345 Q1971.12 270.141 1971.12 276.692 Q1971.12 283.22 1974.11 287.016 Q1977.12 290.813 1982.21 290.813 Q1987.3 290.813 1990.26 287.016 Q1993.25 283.22 1993.25 276.692 Q1993.25 270.141 1990.26 266.345 Q1987.3 262.549 1982.21 262.549 M1982.21 258.753 Q1989.48 258.753 1993.83 263.637 Q1998.18 268.498 1998.18 276.692 Q1998.18 284.864 1993.83 289.748 Q1989.48 294.609 1982.21 294.609 Q1974.92 294.609 1970.54 289.748 Q1966.19 284.887 1966.19 276.692 Q1966.19 268.498 1970.54 263.637 Q1974.92 258.753 1982.21 258.753 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2023.92 280.998 Q2023.92 276.299 2021.98 273.637 Q2020.06 270.952 2016.68 270.952 Q2013.3 270.952 2011.35 273.637 Q2009.43 276.299 2009.43 280.998 Q2009.43 285.697 2011.35 288.382 Q2013.3 291.044 2016.68 291.044 Q2020.06 291.044 2021.98 288.382 Q2023.92 285.697 2023.92 280.998 M2009.43 271.947 Q2010.77 269.632 2012.81 268.521 Q2014.87 267.387 2017.72 267.387 Q2022.44 267.387 2025.38 271.137 Q2028.34 274.887 2028.34 280.998 Q2028.34 287.109 2025.38 290.859 Q2022.44 294.609 2017.72 294.609 Q2014.87 294.609 2012.81 293.498 Q2010.77 292.363 2009.43 290.049 L2009.43 293.938 L2005.15 293.938 L2005.15 257.919 L2009.43 257.919 L2009.43 271.947 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2035.4 268.012 L2039.66 268.012 L2039.66 294.401 Q2039.66 299.354 2037.76 301.576 Q2035.89 303.799 2031.7 303.799 L2030.08 303.799 L2030.08 300.188 L2031.21 300.188 Q2033.64 300.188 2034.52 299.053 Q2035.4 297.942 2035.4 294.401 L2035.4 268.012 M2035.4 257.919 L2039.66 257.919 L2039.66 263.313 L2035.4 263.313 L2035.4 257.919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2070.75 279.91 L2070.75 281.993 L2051.17 281.993 Q2051.45 286.391 2053.81 288.706 Q2056.19 290.998 2060.43 290.998 Q2062.88 290.998 2065.17 290.396 Q2067.49 289.794 2069.76 288.59 L2069.76 292.618 Q2067.46 293.59 2065.06 294.1 Q2062.65 294.609 2060.17 294.609 Q2053.97 294.609 2050.33 290.998 Q2046.72 287.387 2046.72 281.229 Q2046.72 274.864 2050.15 271.137 Q2053.6 267.387 2059.43 267.387 Q2064.66 267.387 2067.7 270.766 Q2070.75 274.123 2070.75 279.91 M2066.49 278.66 Q2066.45 275.165 2064.52 273.081 Q2062.63 270.998 2059.48 270.998 Q2055.91 270.998 2053.76 273.012 Q2051.63 275.026 2051.31 278.683 L2066.49 278.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2096.4 269.007 L2096.4 272.989 Q2094.59 271.993 2092.76 271.507 Q2090.96 270.998 2089.11 270.998 Q2084.96 270.998 2082.67 273.637 Q2080.38 276.252 2080.38 280.998 Q2080.38 285.743 2082.67 288.382 Q2084.96 290.998 2089.11 290.998 Q2090.96 290.998 2092.76 290.512 Q2094.59 290.002 2096.4 289.007 L2096.4 292.942 Q2094.62 293.776 2092.69 294.192 Q2090.8 294.609 2088.64 294.609 Q2082.79 294.609 2079.34 290.928 Q2075.89 287.248 2075.89 280.998 Q2075.89 274.655 2079.36 271.021 Q2082.86 267.387 2088.92 267.387 Q2090.89 267.387 2092.76 267.803 Q2094.64 268.197 2096.4 269.007 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2108.02 260.651 L2108.02 268.012 L2116.79 268.012 L2116.79 271.322 L2108.02 271.322 L2108.02 285.396 Q2108.02 288.567 2108.88 289.47 Q2109.75 290.373 2112.42 290.373 L2116.79 290.373 L2116.79 293.938 L2112.42 293.938 Q2107.49 293.938 2105.61 292.109 Q2103.74 290.257 2103.74 285.396 L2103.74 271.322 L2100.61 271.322 L2100.61 268.012 L2103.74 268.012 L2103.74 260.651 L2108.02 260.651 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2122.39 268.012 L2126.65 268.012 L2126.65 293.938 L2122.39 293.938 L2122.39 268.012 M2122.39 257.919 L2126.65 257.919 L2126.65 263.313 L2122.39 263.313 L2122.39 257.919 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2132.51 268.012 L2137.02 268.012 L2145.13 289.771 L2153.23 268.012 L2157.74 268.012 L2148.02 293.938 L2142.23 293.938 L2132.51 268.012 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip880)\" d=\"M 0 0 M2185.8 279.91 L2185.8 281.993 L2166.21 281.993 Q2166.49 286.391 2168.85 288.706 Q2171.24 290.998 2175.47 290.998 Q2177.93 290.998 2180.22 290.396 Q2182.53 289.794 2184.8 288.59 L2184.8 292.618 Q2182.51 293.59 2180.1 294.1 Q2177.69 294.609 2175.22 294.609 Q2169.01 294.609 2165.38 290.998 Q2161.77 287.387 2161.77 281.229 Q2161.77 274.864 2165.19 271.137 Q2168.64 267.387 2174.48 267.387 Q2179.71 267.387 2182.74 270.766 Q2185.8 274.123 2185.8 279.91 M2181.54 278.66 Q2181.49 275.165 2179.57 273.081 Q2177.67 270.998 2174.52 270.998 Q2170.96 270.998 2168.81 273.012 Q2166.68 275.026 2166.35 278.683 L2181.54 278.66 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "domain = -1.:.1:2.\n",
    "zero_mean(x) = 0.\n",
    "sekernel2 = SE()\n",
    "gp2 = GP(zero_mean, sekernel2)\n",
    "bopt2 = BayesianOptimization(gp2, X, y)\n",
    "conditional(bopt2, X, y, σnoise)\n",
    "\n",
    "scatter(bopt2.X', bopt2.y)\n",
    "plot!(\n",
    "    domain,\n",
    "    bopt2.gp.predictiveMean.(domain),\n",
    "    ribbon=2*sqrt.(bopt2.gp.predictiveVariance.(domain)),\n",
    "    label=\"Mean of GP\"\n",
    ")\n",
    "plot!(domain, blackBoxProcess.(domain; σnoise=0.0), label=\"Objective\") # true objective\n",
    "# bopt.gp.choleskySolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeking an Optimal Value via Expected Improvement\n",
    "Thus far, we've been able to abstract away enough information about bayesian optimization in order to give us a relatively\n",
    "seamless handle on computations of interest. Now, we turn our attention to minimizing our objective function via\n",
    "expected improvement. As a brief aside, we'll derive the analytic representation of expected improvement below:\n",
    "\n",
    "Mathematically, our improvement at x can be expressed as follows: $I(x) = max(Y - f^{*}, 0)$. Where\n",
    "$Y \\sim \\mathcal{N}(\\mu, \\sigma^2)$ is the random variable that corresponds to the function value at x. Since $I$ is a random\n",
    "variable, one can consider the average (expected) improvement (EI) to assess x.\n",
    "\n",
    "$$\n",
    "EI(x) = \\mathbb{E}_{Y \\sim \\mathcal{N}(\\mu, \\sigma^2)}\\left[ I(x) \\right]\n",
    "$$\n",
    "\n",
    "With the reparameterization trick, $Y = \\mu + \\sigma \\epsilon$ where $\\epsilon \\sim \\mathcal{N}(0, 1)$, we have:\n",
    "\n",
    "$$\n",
    "EI(x) = \\mathbb{E}_{\\epsilon \\sim \\mathcal{N}(0, 1)}\\left[ I(x) \\right]\n",
    "$$\n",
    "\n",
    "which can be written as\n",
    "\n",
    "$$\n",
    "EI(x) = \\int_{-\\infty}^{\\infty} I(x) \\phi(\\epsilon) d\\epsilon\n",
    "$$\n",
    "\n",
    "This integral only has a value greater than 0 when $I(x) > 0$. \n",
    "$$\n",
    "\\therefore I(x) > 0 \\Rightarrow EI(x) > 0 \\\\\n",
    "\\Updownarrow \\\\\n",
    "\\mu + \\sigma \\epsilon - f^{*} > 0 \\Rightarrow EI(x) > 0 \\\\\n",
    "\\Updownarrow \\\\\n",
    "\\epsilon > \\frac{f^{*} - \\mu}{\\sigma} \\Rightarrow EI(x) > 0\n",
    "$$\n",
    "\n",
    "Now we solve for $EI(x)$.\n",
    "\n",
    "\\begin{align*}\n",
    "EI(x) &= \\int_{\\frac{f^{*}-\\mu}{\\sigma}}^{\\infty} (\\mu + \\sigma \\epsilon - f^{*}) \\phi(\\epsilon) d\\epsilon\\\\\n",
    "&= (\\mu - f^{*}) \\left[ 1 - \\Phi(\\frac{f^{*} - \\mu}{\\sigma}) \\right] + \\sigma \\phi(\\frac{f^{*} - \\mu}{\\sigma})\n",
    "\\end{align*}\n",
    "\n",
    "But, $EI(x)$ is piecewise, therefore we have the following:\n",
    "\n",
    "$$\n",
    "EI(\\textbf{x}) =\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      (\\mu(\\textbf{x}) - f(\\textbf{x}^*) - \\xi)\\Phi(Z) + \\sigma(\\textbf{x})\\phi(Z) & \\sigma(\\textbf{x}) \\gt 0 \\\\\n",
    "      0 & \\sigma(\\textbf{x}) = 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "Z =\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\frac{\\mu(\\textbf{x}) - f(\\textbf{x}^*) - \\xi}{\\sigma(\\textbf{x})} & \\sigma(\\textbf{x}) \\gt 0 \\\\\n",
    "      0 & \\sigma(\\textbf{x}) = 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ei (generic function with 1 method)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function z(x, bopt::BayesianOptimization)\n",
    "    σ̂(xa) = sqrt(abs(bopt.gp.predictiveVariance(xa)))\n",
    "    μ̂(xa) = bopt.gp.predictiveMean(xa)\n",
    "    f⁺ = bopt.ybest\n",
    "    ξ = .1\n",
    "    return σ̂(x) > 0 ? (μ̂(x) - f⁺ - ξ) / σ̂(x) : 0\n",
    "end\n",
    "\n",
    "function ei(x, bopt::BayesianOptimization)\n",
    "    z_eval = z(x, bopt)\n",
    "    normal = Normal()\n",
    "    normal_cdf_at_z = cdf(normal, z_eval)\n",
    "    normal_pdf_at_z = pdf(normal, z_eval)\n",
    "    σ̂(xa) = abs(sqrt(bopt.gp.predictiveVariance(xa)))\n",
    "    μ̂(xa) = bopt.gp.predictiveMean(xa)\n",
    "    f⁺ = bopt.ybest\n",
    "    ξ = .1\n",
    "    \n",
    "    return σ̂(x) > 0 ? (μ̂(x) - f⁺ - ξ) * normal_cdf_at_z + σ̂(x)*normal_pdf_at_z : 0\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteratively build our plots while conditioning on new data\n",
    "\n",
    "# Setup\n",
    "# Suppose we have some process and we have n known function evaluations\n",
    "n = 2\n",
    "d = 1\n",
    "σnoise = 0.05\n",
    "domain = -1.:.1:2.\n",
    "\n",
    "# Variates and Covariates for initialization\n",
    "X = round.(\n",
    "    rand(Uniform(-10.0, 10.0), d, n), \n",
    "    digits=4\n",
    ") \n",
    "y = vec(blackBoxProcess.(X; σnoise=σnoise))\n",
    "\n",
    "# Initialize our models\n",
    "zero_mean(x) = 0.\n",
    "sekernel = SE()\n",
    "gp = GP(zero_mean, sekernel)\n",
    "bopt = BayesianOptimization(gp, X, y)\n",
    "conditional(bopt, X, y, σnoise)\n",
    "\n",
    "# Keep track of our plots\n",
    "obsAndObjAndGpPlots = [plot(domain, blackBoxProcess.(domain; σnoise=0.0), label=\"Objective\", legend=:outertopleft)]\n",
    "plot!(obsAndObjAndGpPlots[1], bopt.X', bopt.y, seriestype=:scatter)\n",
    "plot!(\n",
    "    obsAndObjAndGpPlots[1],\n",
    "    domain,\n",
    "    bopt.gp.predictiveMean.(domain),\n",
    "    ribbon=2*sqrt.(bopt.gp.predictiveVariance.(domain)),\n",
    "    label=\"μ ± 2σ (GP)\"\n",
    ");\n",
    "\n",
    "# A few iterations of BO\n",
    "BUDGET = 20\n",
    "for budget = 1:BUDGET\n",
    "    # Randomly sample without EI\n",
    "    Xnew = round.(\n",
    "        rand(Uniform(-10.0, 10.0), d, 1),\n",
    "        digits=4\n",
    "    )\n",
    "    ynew = vec(blackBoxProcess.(Xnew; σnoise=σnoise))\n",
    "    \n",
    "    # Update model\n",
    "    conditional(bopt, Xnew, ynew, σnoise)\n",
    "    \n",
    "    # Append plot\n",
    "    push!(obsAndObjAndGpPlots, plot(domain, blackBoxProcess.(domain; σnoise=0.0), label=\"Objective\", legend=:outertopleft))\n",
    "    plot!(obsAndObjAndGpPlots[budget+1], bopt.X', bopt.y, seriestype=:scatter)\n",
    "    plot!(\n",
    "        obsAndObjAndGpPlots[budget+1],\n",
    "        domain,\n",
    "        bopt.gp.predictiveMean.(domain),\n",
    "        ribbon=2sqrt.(bopt.gp.predictiveVariance.(domain)),\n",
    "        label=\"μ ± 2σ (GP)\",\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i = 1:BUDGET\n",
    "    savefig(obsAndObjAndGpPlots[i], \"model0$(i).png\")\n",
    "end\n",
    "# savefig(obsAndObjAndGpPlots[1], \"pic.png\")\n",
    "# plot(obsAndObjAndGpPlots[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Optimization w/Expected Improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.702384620765038\n",
      "-0.702384620765038\n",
      "-0.3034320047270342\n",
      "-0.08592815446987874\n",
      "0.5415606096344738\n",
      "0.5415606096344738\n",
      "0.5415606096344738\n",
      "0.5415606096344738\n",
      "0.5415606096344738\n",
      "0.5415606096344738\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n",
      "0.558693983594186\n"
     ]
    }
   ],
   "source": [
    "# Iteratively build our plots while conditioning on new data\n",
    "\n",
    "# Setup\n",
    "# Suppose we have some process and we have n known function evaluations\n",
    "n = 2\n",
    "d = 1\n",
    "σnoise = 0.05\n",
    "domain = -1.:.1:2.\n",
    "\n",
    "# Variates and Covariates for initialization\n",
    "X = round.(\n",
    "    rand(Uniform(domain[1], domain[end]), d, n), \n",
    "    digits=4\n",
    ") \n",
    "y = vec(blackBoxProcess.(X; σnoise=σnoise))\n",
    "\n",
    "# Initialize our models\n",
    "zero_mean(x) = 0.\n",
    "sekernel = SE()\n",
    "gp = GP(zero_mean, sekernel)\n",
    "bopt = BayesianOptimization(gp, X, y)\n",
    "conditional(bopt, X, y, σnoise)\n",
    "\n",
    "# Keep track of our plots\n",
    "obsAndObjAndGpPlots = [plot(domain, blackBoxProcess.(domain; σnoise=0.0), label=\"Objective\", legend=:outertopleft)]\n",
    "plot!(obsAndObjAndGpPlots[1], bopt.X', bopt.y, seriestype=:scatter)\n",
    "plot!(\n",
    "    obsAndObjAndGpPlots[1],\n",
    "    domain,\n",
    "    bopt.gp.predictiveMean.(domain),\n",
    "    ribbon=2*sqrt.(abs.(bopt.gp.predictiveVariance.(domain))),\n",
    "    label=\"μ ± 2σ (GP)\"\n",
    ");\n",
    "\n",
    "# A few iterations of BO\n",
    "BUDGET = 20\n",
    "for budget = 1:BUDGET\n",
    "    # Find new sample by solving ∇EI = 0\n",
    "    einow(x) = ei(x, bopt)\n",
    "    result = optimize(x -> -einow(first(x)), domain[1], domain[end])\n",
    "    maximizer = [Optim.minimizer(result)]\n",
    "    \n",
    "    # Sample based on recommendation\n",
    "    Xnew = reshape(maximizer, (1, 1))\n",
    "    ynew = vec(blackBoxProcess.(Xnew; σnoise=σnoise))\n",
    "    \n",
    "    # Update model\n",
    "    conditional(bopt, Xnew, ynew, σnoise)\n",
    "    \n",
    "    # Append plot\n",
    "    push!(obsAndObjAndGpPlots, plot(domain, blackBoxProcess.(domain; σnoise=0.0), label=\"Objective\", legend=:outertopleft))\n",
    "    plot!(obsAndObjAndGpPlots[budget+1], bopt.X', bopt.y, seriestype=:scatter)\n",
    "    plot!(\n",
    "        obsAndObjAndGpPlots[budget+1],\n",
    "        domain,\n",
    "        bopt.gp.predictiveMean.(domain),\n",
    "        ribbon=2sqrt.(abs.(bopt.gp.predictiveVariance.(domain))),\n",
    "        label=\"μ ± 2σ (GP)\",\n",
    "    )\n",
    "    \n",
    "    println(bopt.ybest)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i = 1:BUDGET\n",
    "    savefig(obsAndObjAndGpPlots[i], \"model0$(i).png\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3377671437990332"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bopt.ybest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chicken Scratch Below Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Optim [429524aa-4258-5aef-a3af-852621145aeb]\n",
      "└ @ Base loading.jl:1278\n"
     ]
    }
   ],
   "source": [
    "using Optim\n",
    "using Zygote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.878818517601695"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x0 = [0.]\n",
    "result = optimize(x -> -eibar(first(x)), -1.0, 2.0)\n",
    "optimizer = Optim.minimizer(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mMethodError: no method matching Array{T,2} where T(::Array{Float64,1})\u001b[39m\n\u001b[91m\u001b[0mClosest candidates are:\u001b[39m\n\u001b[91m\u001b[0m  Array{T,2} where T(::AbstractArray{S,N}) where {S, N} at boot.jl:428\u001b[39m\n\u001b[91m\u001b[0m  Array{T,2} where T(\u001b[91m::SymTridiagonal{T,V} where V<:AbstractArray{T,1}\u001b[39m) where T at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/tridiag.jl:141\u001b[39m\n\u001b[91m\u001b[0m  Array{T,2} where T(\u001b[91m::Tridiagonal{T,V} where V<:AbstractArray{T,1}\u001b[39m) where T at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/tridiag.jl:582\u001b[39m\n\u001b[91m\u001b[0m  ...\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mMethodError: no method matching Array{T,2} where T(::Array{Float64,1})\u001b[39m\n\u001b[91m\u001b[0mClosest candidates are:\u001b[39m\n\u001b[91m\u001b[0m  Array{T,2} where T(::AbstractArray{S,N}) where {S, N} at boot.jl:428\u001b[39m\n\u001b[91m\u001b[0m  Array{T,2} where T(\u001b[91m::SymTridiagonal{T,V} where V<:AbstractArray{T,1}\u001b[39m) where T at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/tridiag.jl:141\u001b[39m\n\u001b[91m\u001b[0m  Array{T,2} where T(\u001b[91m::Tridiagonal{T,V} where V<:AbstractArray{T,1}\u001b[39m) where T at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/tridiag.jl:582\u001b[39m\n\u001b[91m\u001b[0m  ...\u001b[39m",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[222]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Array{Float64,1}:\n",
       " 0.7789053218266301"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xinit = [0.]\n",
    "einow(x) = -ei(first(x), bopt)\n",
    "result = optimize(einow, xinit, LBFGS())\n",
    "Optim.minimizer(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
