{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiating Rollout Trajectories\n",
    "Bayesian Optimization can be described entirely in 7 steps, adding nuance when necessary:\n",
    "1. Gather initial samples\n",
    "2. Initialize our model\n",
    "3. Get the acquisition function $\\alpha(x)$\n",
    "4. Optimize the acquisition function\n",
    "5. Sample new data based on results from the optimization of $\\alpha(x)$ and update model\n",
    "6. Repeat until budget is exhausted\n",
    "7. Make final recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "post ~ prior * likelikhood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desiderata\n",
    "* Figure out how to update the model by reconditioning the current model on new observations\n",
    "* Construct an API that leverages our computing framework while remaining free of dogmatism when it comes to implementing each step\n",
    "* Elaborate on the nuances of incorporating rollout into the Bayesian Optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CovarianceFunctions\n",
    "using GaussianDistributions\n",
    "using LinearAlgebra\n",
    "using Optim\n",
    "using Plots\n",
    "\n",
    "import Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CovarianceFunctions"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyplot()\n",
    "CF = CovarianceFunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "Here, our objective function is known, but in practice, it usually isn't. We'll be using the d-dimensional [Ackley](https://www.sfu.ca/~ssurjano/ackley.html) function as our objective. Here, we'll let $d=1$.\n",
    "$$\n",
    "f(\\textbf{x}) = -a \\exp \\left( -b \\sqrt{\\frac{1}{d}\\sum\\limits_{i=1}^d x_{i}^2} \\right) - \\exp \\left( \\frac{1}{d} \\sum\\limits_{i=1}^d \\cos(cx_i) \\right) + a + \\exp(1)\n",
    "$$\n",
    "where the recommended variable values are: $a = 20$, $b = 0.2$ and $c=2\\pi$.\n",
    "Also note, the input domain is usually evaluated on the hypercube $x_i \\in [-32.768, 32.768]$, for all $i = 1,...,d$, although it may also be restricted to a smaller domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ackley (generic function with 1 method)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function ackley(x; a=20, b=0.2, c=2π, σnoise=0.0)\n",
    "    term1 = term2 = 0.0\n",
    "    term3 = a\n",
    "    term4 = exp(1)\n",
    "    d = length(x)\n",
    "    \n",
    "    for i in 1:d\n",
    "        term1 += x[i] * x[i]\n",
    "        term2 += cos(c*x[i])\n",
    "    end\n",
    "    \n",
    "    term1 = -a*exp(-b * √(1/d * term1))\n",
    "    term2 = -exp(1/d * term2)\n",
    "    \n",
    "    return -(term1 + term2 + term3 + term4 + σnoise^2*randn())\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Gathering of Initial Samples\n",
    "Suppose that we've observed our rather noisy process and are able to collect n sample points, due to resource constraints, and we wish to make an intelligent query of our process at a later date. First, we'll gather our noisy observations.\n",
    "\n",
    "$$\n",
    "f(\\textbf{x}) = -a \\exp \\left( -b \\sqrt{\\frac{1}{d}\\sum\\limits_{i=1}^d x_{i}^2} \\right) - \\exp \\left( \\frac{1}{d} \\sum\\limits_{i=1}^d \\cos(cx_i) \\right) + a + \\exp(1) + \\epsilon\n",
    "$$\n",
    "where $\\epsilon \\sim \\mathcal{N}(0, \\sigma_{n}^2)$.\n",
    "\n",
    "We then collect our initial sample points, $x_i$ for all $i = 1,...,n$ into our matrix:\n",
    "$$\n",
    "X = \n",
    "\\begin{bmatrix}\n",
    "    \\vert & & \\vert \\\\\n",
    "    x_1   & ... & x_n   \\\\\n",
    "    \\vert & & \\vert\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "For our purposes, we'll let $n_{init} = 3$ and sample $n_{init}$ points on the $d$-dimensional hypercube per detailed earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Array{Float64,1}:\n",
       " -21.560105339981387\n",
       " -21.498424574069425\n",
       "  -0.0004872713367314105\n",
       " -21.508308724323005\n",
       " -21.582103281225436"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "σnoise = 0.1\n",
    "bound = 32.768\n",
    "n_init = 4\n",
    "dim = 1\n",
    "X_init = vec((2bound)rand(dim, n_init) .- bound);\n",
    "X_init = -bound:(2*bound/n_init):bound\n",
    "Y_init = ackley.(X_init; σnoise);\n",
    "# for i = 1:n_init\n",
    "#    Y_init[i] = ackley(X_init[:, i]; σnoise=σnoise) \n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initializing Our Model\n",
    "Our model of choice is a Gaussian process, which is completely defined by its mean function and covariance function.\n",
    "$$\n",
    "\\begin{aligned}\n",
    "m(\\textbf{x}) &= \\mathbb{E}[f(\\textbf{x})],\\\\\n",
    "k(\\textbf{x}, \\textbf{x'}) &= \\mathbb{E}[(f(\\textbf{x}) - m(\\textbf{x}))(f(\\textbf{x'}) - m(\\textbf{x'}))]\n",
    "\\end{aligned}\n",
    "$$\n",
    "and we write the Gaussian process as\n",
    "$$\n",
    "f(\\textbf{x}) \\sim \\mathcal{GP}(m(\\textbf{x}), k(\\textbf{x}, \\textbf{x'}))\n",
    "$$\n",
    "\n",
    "Our covariance function of choice will be the squared exponential kernel, where the hyperparameters must be learned. For the time being, we'll set them manually.\n",
    "<hr>\n",
    "Below, we make use of some interesting developing packages, so further details are required when tracing out our computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: Gaussian not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: Gaussian not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[3]:5",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "ℓ = .5 # set to 0.5 for toy example\n",
    "μ(x) = 0\n",
    "Σ(x, y) = CF.Lengthscale(CF.EQ(), ℓ)(x, y)\n",
    "# Σ(x, y) = CF.Lengthscale(CF.Matern(.5), ℓ)(x, y)\n",
    "GP = Gaussian(μ, Σ)\n",
    "σnoise = 0.01\n",
    "CGP = GP | (X_init, Y_init, σnoise); # when conditioning, x_init must be a column vector\n",
    "\n",
    "# for i in 1:n_init\n",
    "#     CGP = GP | (X_init[:, i], Y_init[i], σnoise)\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Get the Acquisition Function $\\alpha(\\textbf{x})$\n",
    "Here, our acquisition function will be expected improvement, which is defined as:\n",
    "\n",
    "$$\n",
    "EI(\\textbf{x}) = \\mathbb{E} [max(f(\\textbf{x}) - f(\\textbf{x}^+), 0)]\n",
    "$$\n",
    "\n",
    "where $f(\\textbf{x}^+)$ is the value of the best sample so far and $\\textbf{x}^+$ is the location of that sample i.e. $\\textbf{x}^+ = argmax_{x_{i} \\in x_{1:n}}f(\\textbf{x}_i)$. The expected improvement can be evaluated analytically under the GP model:\n",
    "\n",
    "$$\n",
    "EI(\\textbf{x}) =\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      (\\mu(\\textbf{x}) - f(\\textbf{x}^+) - \\xi)\\Phi(Z) + \\sigma(\\textbf{x})\\phi(Z) & \\sigma(\\textbf{x}) \\gt 0 \\\\\n",
    "      0 & \\sigma(\\textbf{x}) = 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "Z =\n",
    "\\left\\{\n",
    "\\begin{array}{ll}\n",
    "      \\frac{\\mu(\\textbf{x}) - f(\\textbf{x}^+) - \\xi}{\\sigma(\\textbf{x})} & \\sigma(\\textbf{x}) \\gt 0 \\\\\n",
    "      0 & \\sigma(\\textbf{x}) = 0 \\\\\n",
    "\\end{array} \n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: mean not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: mean not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[4]:7",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# First, let's grab x+ and f(x+)\n",
    "fbest, fbest_ndx = findmax(Y_init)\n",
    "xbest = X_init[fbest_ndx]\n",
    "\n",
    "# Let's evaluate EI over our domain\n",
    "grid = collect(-bound:.01:bound)\n",
    "μ̂ = mean(CGP)\n",
    "σ̂ = std(CGP)\n",
    "\n",
    "function z(x, f⁺; ξ=0.1)\n",
    "    return σ̂(x) > 0 ? (μ̂(x) - f⁺ - ξ) / σ̂(x) : 0\n",
    "end\n",
    "\n",
    "function ei(x, f⁺; ξ=0.1)\n",
    "    z_eval = z(x, f⁺; ξ=ξ)\n",
    "    normal = Distributions.Normal()\n",
    "    normal_cdf_at_z = Distributions.cdf(normal, z_eval)\n",
    "    normal_pdf_at_z = Distributions.pdf(normal, z_eval)\n",
    "    σ̂eval = σ̂(x)\n",
    "    \n",
    "    return σ̂eval > 0 ? (μ̂(x) - f⁺ - ξ) * normal_cdf_at_z + σ̂(x)*normal_pdf_at_z : 0\n",
    "end\n",
    "\n",
    "# Now to plot the response surface\n",
    "# We want to maximize expected improvement, but our optimization library deals primarily in\n",
    "# minimization, therefore we seek to minimize the negation of expected improvement\n",
    "plot(grid, μ̂.(grid), ribbon=2σ̂.(grid), label=\"GP\")\n",
    "plot!(grid, -ei.(grid, fbest; ξ=.1), label=\"Acquisition Function\")\n",
    "# plot!(grid, ackley.(grid), label=\"Ackley Function\")\n",
    "# plot!(grid, μ̂.(grid), ribbon=2σ̂.(grid), label=\"GP\") # also plot multiple draws from GP\n",
    "Plots.scatter!(X_init, Y_init, label=\"Initial Samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Optimize the Acquisition Function\n",
    "Now that we have a functional handle on our acquisition function, we'll use this to propose our next sample location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "\u001b[91mUndefVarError: LBFGS not defined\u001b[39m",
     "output_type": "error",
     "traceback": [
      "\u001b[91mUndefVarError: LBFGS not defined\u001b[39m",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[5]:3",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "# Is it worthwhile keeping track of the best to date?\n",
    "ei_fbest(x) = -ei(x[1], fbest) # want some auto differentiation here\n",
    "result = optimize(ei_fbest, [0.0], LBFGS())\n",
    "xnew = Optim.minimizer(result)\n",
    "println(\"Minimum: $(Optim.minimum(result))\\nMinimizer: $(Optim.minimizer(result))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Sample New Data Based on Results from the Optimization of $\\alpha(x)$ and Update Model\n",
    "Now we want to evaluate the objective function at our new proposed location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "301-element Array{Float64,1}:\n",
       " -22.27258061196509\n",
       " -17.496827175598902\n",
       " -13.482078410834532\n",
       "  -4.39021483032714\n",
       " -22.238391058990963\n",
       " -17.882817224558604\n",
       " -20.80784288272934\n",
       " -20.336880029805034\n",
       " -20.37997483739859\n",
       " -12.491678162514818\n",
       " -19.909265617706385\n",
       " -20.04051128096096\n",
       " -20.210434380143756\n",
       "   ⋮\n",
       " -18.109233710137776\n",
       " -14.127671559266206\n",
       " -15.960956989235566\n",
       " -20.462122480517817\n",
       " -22.268056073117165\n",
       " -21.41405550659043\n",
       " -21.664813960876835\n",
       " -22.196456534977468\n",
       " -20.09950594890019\n",
       " -21.910833783096724\n",
       " -21.155178349320856\n",
       "   3.24767380990712e-5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "push!(X_init, xnew[1])\n",
    "push!(Y_init, ackley(xnew[1]; σnoise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update our model\n",
    "# Replot acquisition, samples and objective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching sample(::Gaussian{GaussianDistributions.ConditionalMean{Gaussian{typeof(μ),typeof(Σ)},Array{Float64,1},Array{Float64,1}},GaussianDistributions.ConditionalKernel{Float64,typeof(Σ),Array{Float64,1},LazyInverse.Inverse{Float64,WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}}}}, ::Int64)\nClosest candidates are:\n  sample(!Matched::AbstractArray, ::Integer; replace, ordered) at /Users/jamosa/.julia/packages/StatsBase/EA8Mh/src/sampling.jl:461\n  sample(!Matched::Gaussian{var\"#s21\",var\"#s20\"} where var\"#s20\"<:Cholesky where var\"#s21\"<:(AbstractArray{T,1} where T), ::Int64; tol) at /Users/jamosa/.julia/packages/GaussianDistributions/AUZIQ/src/sample.jl:24\n  sample(!Matched::Gaussian{var\"#s21\",var\"#s20\"} where var\"#s20\"<:CholeskyPivoted where var\"#s21\"<:(AbstractArray{T,1} where T), ::Int64; tol) at /Users/jamosa/.julia/packages/GaussianDistributions/AUZIQ/src/sample.jl:27\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching sample(::Gaussian{GaussianDistributions.ConditionalMean{Gaussian{typeof(μ),typeof(Σ)},Array{Float64,1},Array{Float64,1}},GaussianDistributions.ConditionalKernel{Float64,typeof(Σ),Array{Float64,1},LazyInverse.Inverse{Float64,WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}}}}, ::Int64)\nClosest candidates are:\n  sample(!Matched::AbstractArray, ::Integer; replace, ordered) at /Users/jamosa/.julia/packages/StatsBase/EA8Mh/src/sampling.jl:461\n  sample(!Matched::Gaussian{var\"#s21\",var\"#s20\"} where var\"#s20\"<:Cholesky where var\"#s21\"<:(AbstractArray{T,1} where T), ::Int64; tol) at /Users/jamosa/.julia/packages/GaussianDistributions/AUZIQ/src/sample.jl:24\n  sample(!Matched::Gaussian{var\"#s21\",var\"#s20\"} where var\"#s20\"<:CholeskyPivoted where var\"#s21\"<:(AbstractArray{T,1} where T), ::Int64; tol) at /Users/jamosa/.julia/packages/GaussianDistributions/AUZIQ/src/sample.jl:27\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[332]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "sample(CGP, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.33496302188486926"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(Gaussian())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gaussian{GaussianDistributions.ConditionalMean{Gaussian{typeof(μ),typeof(Σ)},Array{Float64,1},Array{Float64,1}},GaussianDistributions.ConditionalKernel{Float64,typeof(Σ),Array{Float64,1},LazyInverse.Inverse{Float64,WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}}}}(GaussianDistributions.ConditionalMean{Gaussian{typeof(μ),typeof(Σ)},Array{Float64,1},Array{Float64,1}}(Gaussian{typeof(μ),typeof(Σ)}(μ, Σ), [17.584579592225538, -7.075117479705469, -25.208144779417097, 28.68964575520068, -18.714588423050024], [-19.713076157940634, -14.018902153501159, -17.77878035309405, -19.934906450951814, -17.927134533869236]), GaussianDistributions.ConditionalKernel{Float64,typeof(Σ),Array{Float64,1},LazyInverse.Inverse{Float64,WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}}}(Σ, [17.584579592225538, -7.075117479705469, -25.208144779417097, 28.68964575520068, -18.714588423050024], LazyInverse.Inverse{Float64,WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}}(WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}([10.0 0.0 … 0.0 0.0; 0.0 10.0 … 0.0 0.0; … ; 0.0 0.0 … 10.0 0.0; 0.0 0.0 … 0.0 10.0], [10.0 0.0 … 0.0 0.0; 2.1284763874791185e-14 10.0 … 0.0 0.0; … ; 0.010581325249019941 -2.252210094077417e-17 … 9.999994401776233 0.0; 1.617818455116978e-31 0.005386116385416363 … 1.2130647249073825e-20 9.95373438612923], LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}}(Cholesky{Float64,Array{Float64,2}}([3.3166264782824735 6.417587323383496e-15 … 0.003190386193514581 4.855335773460839e-32; 2.128474004342365e-14 3.3166252277013415 … -1.296398020245627e-17 0.0016164615593414473; … ; 0.01058131932535729 -2.2522081798690303e-17 … 3.316621567950063 9.876118515232823e-21; 1.6103335187212336e-31 0.005361197187321294 … 1.207452406491101e-20 3.29017095473349], 'U', 0)), [10.0 2.1284763874791185e-14 … 0.010581325249019941 1.617818455116978e-31; 0.0 10.0 … -2.252210094077417e-17 0.005386116385416363; … ; 0.0 0.0 … 9.999994401776233 1.2130647249073825e-20; 0.0 0.0 … 0.0 9.95373438612923], -1, (-0.4688912012640394, 1.0)))))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching cholesky(::GaussianDistributions.ConditionalKernel{Float64,typeof(Σ),Array{Float64,1},LazyInverse.Inverse{Float64,WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}}})\nClosest candidates are:\n  cholesky(!Matched::Union{Hermitian{Complex{T},SparseArrays.SparseMatrixCSC{Complex{T},Int64}}, Hermitian{T,SparseArrays.SparseMatrixCSC{T,Int64}}, Symmetric{T,SparseArrays.SparseMatrixCSC{T,Int64}}, SparseArrays.SparseMatrixCSC{T,Ti} where Ti<:Integer, SparseArrays.SparseMatrixCSC{Complex{T},Ti} where Ti<:Integer}; kws...) where T<:Real at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/SuiteSparse/src/cholmod.jl:1458\n  cholesky(!Matched::Union{StridedArray{T, 2} where T, Union{Hermitian{var\"#s823\",var\"#s822\"}, Hermitian{Complex{var\"#s823\"},var\"#s822\"}, Symmetric{var\"#s823\",var\"#s822\"}} where var\"#s822\"<:(StridedArray{T, 2} where T) where var\"#s823\"<:Real}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/cholesky.jl:344\n  cholesky(!Matched::Union{StridedArray{T, 2} where T, Union{Hermitian{var\"#s821\",var\"#s820\"}, Hermitian{Complex{var\"#s821\"},var\"#s820\"}, Symmetric{var\"#s821\",var\"#s820\"}} where var\"#s820\"<:(StridedArray{T, 2} where T) where var\"#s821\"<:Real}, !Matched::Val{false}; check) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/cholesky.jl:344\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching cholesky(::GaussianDistributions.ConditionalKernel{Float64,typeof(Σ),Array{Float64,1},LazyInverse.Inverse{Float64,WoodburyIdentity.Woodbury{Float64,Diagonal{Float64,Array{Float64,1}},Array{Float64,2},LazyInverse.Inverse{Float64,Cholesky{Float64,Array{Float64,2}}},Adjoint{Float64,Array{Float64,2}},Int64,Tuple{Float64,Float64}}}})\nClosest candidates are:\n  cholesky(!Matched::Union{Hermitian{Complex{T},SparseArrays.SparseMatrixCSC{Complex{T},Int64}}, Hermitian{T,SparseArrays.SparseMatrixCSC{T,Int64}}, Symmetric{T,SparseArrays.SparseMatrixCSC{T,Int64}}, SparseArrays.SparseMatrixCSC{T,Ti} where Ti<:Integer, SparseArrays.SparseMatrixCSC{Complex{T},Ti} where Ti<:Integer}; kws...) where T<:Real at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/SuiteSparse/src/cholmod.jl:1458\n  cholesky(!Matched::Union{StridedArray{T, 2} where T, Union{Hermitian{var\"#s823\",var\"#s822\"}, Hermitian{Complex{var\"#s823\"},var\"#s822\"}, Symmetric{var\"#s823\",var\"#s822\"}} where var\"#s822\"<:(StridedArray{T, 2} where T) where var\"#s823\"<:Real}) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/cholesky.jl:344\n  cholesky(!Matched::Union{StridedArray{T, 2} where T, Union{Hermitian{var\"#s821\",var\"#s820\"}, Hermitian{Complex{var\"#s821\"},var\"#s820\"}, Symmetric{var\"#s821\",var\"#s820\"}} where var\"#s820\"<:(StridedArray{T, 2} where T) where var\"#s821\"<:Real}, !Matched::Val{false}; check) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/cholesky.jl:344\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[25]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "cholesky(CGP.Σ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "MethodError: no method matching factorize(::Gaussian{typeof(μ),typeof(Σ)}; tol=1.0e-5)\nClosest candidates are:\n  factorize(!Matched::StridedArray{T, 2}) where T at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/dense.jl:1207 got unsupported keyword argument \"tol\"\n  factorize(!Matched::Adjoint) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/dense.jl:1283 got unsupported keyword argument \"tol\"\n  factorize(!Matched::Transpose) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/dense.jl:1284 got unsupported keyword argument \"tol\"\n  ...",
     "output_type": "error",
     "traceback": [
      "MethodError: no method matching factorize(::Gaussian{typeof(μ),typeof(Σ)}; tol=1.0e-5)\nClosest candidates are:\n  factorize(!Matched::StridedArray{T, 2}) where T at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/dense.jl:1207 got unsupported keyword argument \"tol\"\n  factorize(!Matched::Adjoint) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/dense.jl:1283 got unsupported keyword argument \"tol\"\n  factorize(!Matched::Transpose) at /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.5/LinearAlgebra/src/dense.jl:1284 got unsupported keyword argument \"tol\"\n  ...",
      "",
      "Stacktrace:",
      " [1] top-level scope at In[32]:1",
      " [2] include_string(::Function, ::Module, ::String, ::String) at ./loading.jl:1091"
     ]
    }
   ],
   "source": [
    "factorize(Gaussian(μ, Σ), tol=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.3",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
